{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#  the split_size gives how much of the data goes to the train/test.    \n",
    "def read_data(base_path='./Data',split_size=[0.6, 0.2, 0.2]):  \n",
    "    \"\"\"\n",
    "    Reads all of the .mat files in the given base_path, and returns a dict with the data found there.\n",
    "    :param split_size:\n",
    "    :param base_path: The directory that should be read in.\n",
    "    :return: a dict, containing the EES and difference tensors.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for file in os.listdir(base_path):\n",
    "        i = i + 1\n",
    "    pbar = tqdm(total=i)\n",
    "\n",
    "    data_dict = {}\n",
    "    for file in os.listdir(base_path):\n",
    "        num, data_type = file.split('_')\n",
    "        data_type = data_type.split('.')[0]\n",
    "        num = int(num)\n",
    "        if \"EES\" in data_type:\n",
    "            tensor_in = sio.loadmat(os.path.join(base_path, file))['EES_value']\n",
    "            tensor_in = torch.FloatTensor(tensor_in).squeeze(0)\n",
    "        else:\n",
    "            tensor_in = sio.loadmat(os.path.join(base_path, file))['Kulonbseg']\n",
    "            tensor_in = torch.FloatTensor(tensor_in)\n",
    "        try:\n",
    "            data_dict[num][data_type] = tensor_in\n",
    "        except KeyError:\n",
    "            data_dict[num] = {data_type: tensor_in}\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "\n",
    "    new_data = []\n",
    "    for key in data_dict.keys():\n",
    "        new_data.append(data_dict[key])\n",
    "    np.random.shuffle(new_data)\n",
    "    if isinstance(split_size, list):\n",
    "        training_samples = int(split_size[0] * len(new_data))\n",
    "        valid_samples = int(split_size[1] * len(new_data))\n",
    "        test_samples = int(split_size[2] * len(new_data))\n",
    "        while sum([training_samples, valid_samples, test_samples]) != len(new_data):\n",
    "            training_samples += 1\n",
    "        #split samples\n",
    "        new_datadict = {'train': new_data[ : training_samples],\n",
    "                        'validation': new_data[training_samples : training_samples + valid_samples],\n",
    "                        'test': new_data[-test_samples : ]}\n",
    "        \n",
    "    else:\n",
    "        new_datadict = {'train': new_data,\n",
    "                        'validation': new_data,\n",
    "                        'test': new_data}\n",
    "    print(\"Adatbetöltés kész\")\n",
    "    return new_datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the data and get the splitted dataset\n",
    "dataset = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classificator:\n",
    "\n",
    "    #-------------------------\n",
    "    # Label   Class\n",
    "    #-------------------------\n",
    "    # 0:      Not damaged\n",
    "    # 1:      Slightly damaged\n",
    "    # 2:      Damaged\n",
    "    # 3:      Very damaged\n",
    "    #-------------------------\n",
    "    \n",
    "    def getClassName(self, c):\n",
    "        if c==0:\n",
    "            n = \"Not Damaged\"\n",
    "        elif c==1:\n",
    "            n = \"Slightly damaged\"\n",
    "        elif c==2:\n",
    "            n = \"Damaged\"\n",
    "        elif c==3:\n",
    "            n = \"Very damaged\"\n",
    "        return n;\n",
    "    \n",
    "    def getClass(self, x):\n",
    "        x = int(x)\n",
    "        \n",
    "        if x==0:\n",
    "            return 0      \n",
    "        if x<=100/3:\n",
    "            return 1\n",
    "        elif  x>100/3 and x<200/3:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "    \n",
    "    # Compare Prediction and Label classes\n",
    "    def isCorrect(self, prediction, label):\n",
    "        return self.getClass(prediction) == self.getClass(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "class CarBadnessGuesser(nn.Module):\n",
    "    def __init__(self, lr=0.01):\n",
    "        super(CarBadnessGuesser, self).__init__()\n",
    "\n",
    "        self.valid_freq = 10\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=1, out_channels=3, kernel_size=(10, 5, 5), stride=(10, 5, 5)),\n",
    "            nn.BatchNorm3d(3),\n",
    "            nn.Conv3d(in_channels=3, out_channels=2, kernel_size=5),\n",
    "            nn.BatchNorm3d(2),\n",
    "            nn.Conv3d(in_channels=2, out_channels=1, kernel_size=3),\n",
    "            nn.BatchNorm3d(1),\n",
    "            nn.AdaptiveMaxPool3d((1, 1, 10)),\n",
    "        ) \n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=10, out_features=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=5, out_features=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        if torch.cuda.is_available():\n",
    "            self.linear.cuda()\n",
    "            self.model.cuda()\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(list(self.model.parameters()) + list(self.linear.parameters()), lr=lr)\n",
    "        \n",
    "        self.classificator = Classificator()\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.model(x.unsqueeze(0).unsqueeze(0))\n",
    "        return self.linear(conv_out.squeeze(-2).squeeze(-2))\n",
    "\n",
    "    def train(self, epochs=50):\n",
    "        b_loss = []\n",
    "        v_loss = []\n",
    "    \n",
    "        for epoch in trange(epochs):\n",
    "            t_correct = 0\n",
    "            total = 0\n",
    "            for step, data in enumerate(dataset[\"train\"]):\n",
    "                input_data = data['KUL'].cuda()\n",
    "                label = data['EES'].cuda()\n",
    "                \n",
    "                prediction = self(input_data)\n",
    "                loss = self.loss_fn(prediction, label)\n",
    "                #print('training- ', 'y^', prediction.item(), 'y', label.item(), loss.item())\n",
    "                \n",
    "                loss.backward()     \n",
    "                self.optimizer.step()\n",
    "                b_loss.append(loss.item())\n",
    "                \n",
    "                #check if its prediction matches label class\n",
    "                if( self.classificator.isCorrect(prediction.item(), label.item()) ):\n",
    "                    t_correct += 1;\n",
    "                total += 1;\n",
    "                \n",
    "                self.zero_grad()\n",
    "            if epoch % self.valid_freq and epoch != 0:\n",
    "                #calculate the training accuracy\n",
    "                t_acc = t_correct/total * 100\n",
    "                #print(f'Batch loss: {loss.item()}', flush=True)\n",
    "             \n",
    "                vloss, v_acc = self.validation()\n",
    "                v_loss.append(vloss)\n",
    "                print(f'Validation loss:', vloss, flush=True)\n",
    "\n",
    "                \n",
    "        print('Training acc:', t_acc, '%')\n",
    "        print('Validation acc: ', v_acc, '%')  \n",
    "        plt.plot(v_loss)\n",
    "        plt.ylabel('Validation loss')\n",
    "        plt.show()\n",
    "        plt.plot(b_loss)\n",
    "        plt.ylabel('Batch loss')\n",
    "        plt.show()\n",
    "\n",
    "    def validation(self):\n",
    "        \"\"\"\n",
    "        Runs the validation phase of the training\n",
    "        :return: The validation loss average\n",
    "        \"\"\"\n",
    "        v_correct = 0\n",
    "        total = 0\n",
    "        average_loss = 0\n",
    "        step = 0\n",
    "        \n",
    "        for step, data in enumerate(dataset['validation']):\n",
    "            with torch.no_grad():\n",
    "                input_data = data['KUL'].cuda()\n",
    "                label = data['EES'].cuda()\n",
    "                \n",
    "                prediction = self(input_data)\n",
    "                loss = self.loss_fn(prediction, label)               \n",
    "                #print('validation- ', 'y^', prediction.item(), 'y', label.item(), loss.item())\n",
    "                #print('v_correct', v_correct, 'total',total)\n",
    "                \n",
    "                average_loss += loss.item()\n",
    "                \n",
    "                #check if its correct\n",
    "                c = self.classificator.isCorrect(prediction.item(), label.item())\n",
    "                if(c == True):\n",
    "                    v_correct += 1;\n",
    "                total += 1;\n",
    "        \n",
    "        #calculate the validation accuracy\n",
    "        v_acc = v_correct/total * 100\n",
    "        return average_loss / (step + 1), v_acc\n",
    "        print(\"Validation is complete\")\n",
    "        \n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Runs the evaluation of the network.\n",
    "        :return: average loss for the test\n",
    "        \"\"\"\n",
    "        t_correct = 0\n",
    "        total = 0\n",
    "        average_loss = 0\n",
    "        step = 0\n",
    "        \n",
    "        for step, data in enumerate(dataset['test']):\n",
    "            with torch.no_grad():\n",
    "                input_data = data['KUL'].cuda()\n",
    "                prediction = self(input_data)\n",
    "                \n",
    "                loss = self.loss_fn(prediction, data['EES'].cuda())\n",
    "                \n",
    "                print('---------------------------------')\n",
    "                print()\n",
    "                print('Prediction: ', prediction.item())\n",
    "                print('Excpected:  ', data['EES'].cuda().item())   \n",
    "                print()\n",
    "                prediction_label = self.classificator.getClass(prediction.item())\n",
    "                print('Class:          ', self.classificator.getClassName(prediction_label))\n",
    "                expected_label = self.classificator.getClass(data['EES'].cuda())\n",
    "                print('Expected Class: ', self.classificator.getClassName(expected_label))\n",
    "                print()\n",
    "                print('loss: ', loss.item())\n",
    "                print()\n",
    "                \n",
    "                #check if its correct\n",
    "                c = self.classificator.isCorrect(prediction.item(), data['EES'].cuda().item())\n",
    "                if(c == True):\n",
    "                    t_correct += 1;\n",
    "                total += 1;\n",
    "                \n",
    "                average_loss += loss.item()\n",
    "\n",
    "        #calculate the validation accuracy\n",
    "        t_acc = t_correct/total * 100          \n",
    "        average_loss = average_loss / step   \n",
    "        print()\n",
    "        print('---------------------------------')\n",
    "        print('Test Accuracy: ', t_acc, ' %')\n",
    "        print('Average Loss:  ', average_loss)\n",
    "        print('---------------------------------')\n",
    "        print()\n",
    "        print(\"Test is completed\")       \n",
    "        return average_loss\n",
    "\n",
    "\n",
    "    def save_weights(self, save_dir=\"./training\"):\n",
    "        \"\"\"\n",
    "        Saves weights to the given directory plus the timestamp\n",
    "        :return: none\n",
    "        \"\"\"\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S.%d\")\n",
    "        save_path = os.path.join(save_dir, timestamp)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        # save model within Training folder with timestamp together with preivous models\n",
    "        torch.save(self.state_dict(), os.path.join(save_path, 'model.weights'))\n",
    "        # save last model within Weights folder (overwrite)\n",
    "        torch.save(self.state_dict(), './weights/model.weights')\n",
    "\n",
    "    def load_weights(self):\n",
    "        self.load_state_dict = torch.load('./weights/model.weights')\n",
    "        print(\"loading weights is complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # set mode\n",
    "    TRAIN = True\n",
    "    TEST = True\n",
    "    \n",
    "    # instanciate the NN\n",
    "    net = CarBadnessGuesser()\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "    # Train, Validate and Save the model\n",
    "    if(TRAIN):\n",
    "        net.train()\n",
    "        net.save_weights()\n",
    "    \n",
    "    # Load the model and Test\n",
    "    if(TEST):\n",
    "        net.load_weights()\n",
    "        net.test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
