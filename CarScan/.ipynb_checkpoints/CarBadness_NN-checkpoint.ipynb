{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "def read_data(base_path='./Data',split_size=[0.6, 0.2, 0.2]):  #  the split_size gives how much of the data goes to the train/test.\n",
    "    \"\"\"\n",
    "    Reads all of the .mat files in the given base_path, and returns a dict with the data found there.\n",
    "    :param split_size:\n",
    "    :param base_path: The directory that should be read in.\n",
    "    :return: a dict, containing the EES and difference tensors.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for file in os.listdir(base_path):\n",
    "        i = i + 1\n",
    "    pbar = tqdm(total=i)\n",
    "\n",
    "    data_dict = {}\n",
    "    for file in os.listdir(base_path):\n",
    "        num, data_type = file.split('_')\n",
    "        data_type = data_type.split('.')[0]\n",
    "        num = int(num)\n",
    "        if \"EES\" in data_type:\n",
    "            tensor_in = sio.loadmat(os.path.join(base_path, file))['EES_value']\n",
    "            tensor_in = torch.FloatTensor(tensor_in).squeeze(0)\n",
    "        else:\n",
    "            tensor_in = sio.loadmat(os.path.join(base_path, file))['Kulonbseg']\n",
    "            tensor_in = torch.FloatTensor(tensor_in)\n",
    "        try:\n",
    "            data_dict[num][data_type] = tensor_in\n",
    "        except KeyError:\n",
    "            data_dict[num] = {data_type: tensor_in}\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "\n",
    "    new_data = []\n",
    "    for key in data_dict.keys():\n",
    "        new_data.append(data_dict[key])\n",
    "    np.random.shuffle(new_data)\n",
    "    if isinstance(split_size, list):\n",
    "        training_samples = int(split_size[0] * len(new_data))\n",
    "        valid_samples = int(split_size[1] * len(new_data))\n",
    "        test_samples = int(split_size[2] * len(new_data))\n",
    "        while sum([training_samples, valid_samples, test_samples]) != len(new_data):\n",
    "            training_samples += 1\n",
    "        #split samples\n",
    "        new_datadict = {'train': new_data[:training_samples],\n",
    "                        'validation': new_data[training_samples + 1:training_samples + valid_samples],\n",
    "                        'test': new_data[-test_samples:]}\n",
    "    else:\n",
    "        new_datadict = {'train': new_data,\n",
    "                        'validation': new_data,\n",
    "                        'test': new_data}\n",
    "    print(\"Adatbetöltés kész\")\n",
    "    return new_datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-ba68d470b213>, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-ba68d470b213>\"\u001b[1;36m, line \u001b[1;32m73\u001b[0m\n\u001b[1;33m    if( self.isCorrect(prediction.item(), label.item()))\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class CarBadnessGuesser(nn.Module):\n",
    "    def __init__(self, lr=0.01):\n",
    "        super(CarBadnessGuesser, self).__init__()\n",
    "\n",
    "        self.dataset = read_data()\n",
    "        self.valid_freq = 10\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=1, out_channels=3, kernel_size=(10, 5, 5), stride=(10, 5, 5)),\n",
    "            nn.BatchNorm3d(3),\n",
    "            nn.Conv3d(in_channels=3, out_channels=2, kernel_size=5),\n",
    "            nn.BatchNorm3d(2),\n",
    "            nn.Conv3d(in_channels=2, out_channels=1, kernel_size=3),\n",
    "            nn.BatchNorm3d(1),\n",
    "            nn.AdaptiveMaxPool3d((1, 1, 10)),\n",
    "        ) \n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=10, out_features=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=5, out_features=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        if torch.cuda.is_available():\n",
    "            self.linear.cuda()\n",
    "            self.model.cuda()\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(list(self.model.parameters()) + list(self.linear.parameters()), lr=lr)\n",
    "\n",
    "\n",
    "    # 0: no damage, 1: slightly damaged, 2: damaged, 3: very damaged\n",
    "    def getClass(self, x):\n",
    "        if x==0:\n",
    "            return 0      \n",
    "        x = int(x)\n",
    "        if x<=100/3:\n",
    "            return 1\n",
    "        elif  x>100/3 and x<200/3:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "    \n",
    "    # compare prediction and label classes\n",
    "    def isCorrect(self, prediction, label):\n",
    "        return self.getClass(prediction) == self.getClass(label)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.model(x.unsqueeze(0).unsqueeze(0))\n",
    "        return self.linear(conv_out.squeeze(-2).squeeze(-2))\n",
    "\n",
    "    def train(self, epochs=50):\n",
    "        b_loss = []\n",
    "        v_loss = []\n",
    "    \n",
    "        for epoch in trange(epochs):\n",
    "            t_correct = 0\n",
    "            total = 1\n",
    "            for step, data in enumerate(self.dataset[\"train\"]):\n",
    "                input_data = data['KUL'].cuda()\n",
    "                label = data['EES'].cuda()\n",
    "                \n",
    "                prediction = self(input_data)\n",
    "                loss = self.loss_fn(prediction, label)\n",
    "                #print('training- ', 'y^', prediction.item(), 'y', label.item(), loss.item())\n",
    "                #print('t_correct', t_correct, 'total',total)\n",
    "                \n",
    "                loss.backward()     \n",
    "                self.optimizer.step()\n",
    "                b_loss.append(loss.item())\n",
    "                \n",
    "                #check if its prediction matches label class\n",
    "                if( self.isCorrect(prediction.item(), label.item()) ):\n",
    "                    t_correct += 1;\n",
    "                total += 1;\n",
    "                \n",
    "                self.zero_grad()\n",
    "            if epoch % self.valid_freq and epoch != 0:\n",
    "                #calculate the training accuracy\n",
    "                t_acc = t_correct/total * 100\n",
    "                #print(f'Batch loss: {loss.item()}', flush=True)\n",
    "             \n",
    "                vloss, v_acc = self.validation()\n",
    "                v_loss.append(vloss)\n",
    "                print(f'Validation loss:', vloss, flush=True)\n",
    "\n",
    "                \n",
    "        print('Training acc:', t_acc, '%')\n",
    "        print('Validation acc: ', v_acc, '%')  \n",
    "        self.save_weights()\n",
    "        \n",
    "        plt.plot(v_loss)\n",
    "        plt.ylabel('Validation loss')\n",
    "        plt.show()\n",
    "        plt.plot(b_loss)\n",
    "        plt.ylabel('Batch loss')\n",
    "        plt.show()\n",
    "\n",
    "    def validation(self):\n",
    "        \"\"\"\n",
    "        Runs the validation phase of the training\n",
    "        :return: The validation loss average\n",
    "        \"\"\"\n",
    "        v_correct = 0\n",
    "        total = 1\n",
    "        average_loss = 0\n",
    "        step = 0\n",
    "        \n",
    "        for step, data in enumerate(self.dataset['validation']):\n",
    "            with torch.no_grad():\n",
    "                input_data = data['KUL'].cuda()\n",
    "                label = data['EES'].cuda()\n",
    "                \n",
    "                prediction = self(input_data)\n",
    "                loss = self.loss_fn(prediction, label)               \n",
    "                #print('validation- ', 'y^', prediction.item(), 'y', label.item(), loss.item())\n",
    "                #print('v_correct', v_correct, 'total',total)\n",
    "                \n",
    "                average_loss += loss.item()\n",
    "                \n",
    "                #check if its correct\n",
    "                c = self.isCorrect(prediction.item(), label.item())\n",
    "                if(c == True):\n",
    "                    v_correct += 1;\n",
    "                total += 1;\n",
    "        \n",
    "        #calculate the validation accuracy\n",
    "        v_correct = v_correct/total * 100  \n",
    "        return average_loss / (step + 1), v_correct\n",
    "        print(\"Validation is complete\")\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Runs the evaluation of the network.\n",
    "        :return: average loss for the test\n",
    "        \"\"\"\n",
    "        average_loss = 0\n",
    "        step = 0\n",
    "        for step, data in enumerate(self.dataset['test']):\n",
    "            with torch.no_grad():\n",
    "                input_data = data['KUL'].cuda()\n",
    "                prediction = self(input_data)\n",
    "                loss = self.loss_fn(prediction, data['EES'].cuda())\n",
    "                average_loss += loss.item()\n",
    "        return average_loss / step\n",
    "        print(\"the test is complete\")\n",
    "\n",
    "    def save_weights(self, save_dir=\"./training\"):\n",
    "        \"\"\"\n",
    "        Saves weights to the given directory plus the timestamp\n",
    "        :return: none\n",
    "        \"\"\"\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S.%d\")\n",
    "        save_path = os.path.join(save_dir, timestamp)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        torch.save(list(self.model.parameters()) +\n",
    "                   list(self.linear.parameters()), os.path.join(save_path, 'model.weights'))\n",
    "        print(\"saving weights is complete\")\n",
    "\n",
    "    def load_weights(self):\n",
    "        self.optimizer = torch.load('model.weights')\n",
    "        print(\"loading is complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    learner = CarBadnessGuesser()\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    learner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
